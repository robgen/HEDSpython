{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/robgen/HEDSpython/blob/main/Tutorial_4.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "TCx6IDFBvhU8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LudlcStpotBm"
      },
      "source": [
        "# **Pandas**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVJzm2D0ork5"
      },
      "source": [
        "Pandas is an open source Python library for data analysis. Most of the times it is pre-installed in your system, but, as for any other library, you need to import it.\n",
        "\n",
        "Let's start with importing pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD2s1_-ho2cO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MSwCYQlpo5b"
      },
      "source": [
        "Let's import a dataset. To do so we use the `read_csv()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQbafUZIqTYX"
      },
      "outputs": [],
      "source": [
        "# csvFilePath = 'files/internallyDisplaced.csv'\n",
        "csvFilePath = \"https://raw.githubusercontent.com/robgen/HEDSpython/refs/heads/main/files/internallyDisplaced.csv\"\n",
        "internallyDisplaced = pd.read_csv(csvFilePath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP1-HG0aridl"
      },
      "source": [
        "You can also read excel files with the `read_excel()` function. The rest is the same you just need to define the right file path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNa3WlC3t2lw"
      },
      "source": [
        "## **Inspecting a dataframe**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWNJXfdMt7MC"
      },
      "source": [
        "The methods `.head()` and `.tail()` show respectively the first and last 5 rows of a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrGMtmVztvH6"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S2nJ2VUvo_H"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9S0quFhvV9q"
      },
      "source": [
        "You can also give the number of rows that you want to show as an argument to the method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pw-OvyJLvegB"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzfVoIOyvwf2"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cVNORp13B-g"
      },
      "source": [
        "The attribute `.shape` returns the dimensions (rows, columns) of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEKq89HW3JuZ"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxE1OQUA3akQ"
      },
      "source": [
        "You can use the `.sample()` method to show a random number of rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD5EzRev3bs5"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6qAlDCC3pA-"
      },
      "source": [
        "If you re-run the line of code above you will see that the selection of rows will change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffHOh28zxoZN"
      },
      "source": [
        "## **Selecting columns and rows in Pandas**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to check which columns are in the dataframe is"
      ],
      "metadata": {
        "id": "8luhx2qnuz1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "internallyDisplaced.columns"
      ],
      "metadata": {
        "id": "NFXPN7haujKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkmPu7-Uxsj2"
      },
      "source": [
        "You can select a single column in the following way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pm-piEjmx42w"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['Name']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oem9yFngHZ1j"
      },
      "source": [
        "Or in the following way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNirJcATHciN"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.Name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ehcv97CyKaP"
      },
      "source": [
        "To select multiple columns you need to parse the column names as a list within the first [].\n",
        "\n",
        "An example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXxXibY9ypLh"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced[['Hazard Type', 'Name']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q8E-wXBzsdf"
      },
      "source": [
        "You can compare column items against a certain value. Doing so will return `True` or `False` for each item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZC1z2BdzgcO"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['Hazard Type'] == 'Flood'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIXDMRNG0MdH"
      },
      "source": [
        "You can use such comparison to select specific rows in a dataframe (i.e., those that meet the stated condition)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxyhaqif0ZD6"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced[internallyDisplaced['Hazard Type'] == 'Flood']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbLwozfN0hpM"
      },
      "source": [
        "You can also combine different conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A1ns-Ii0k9G"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced[(internallyDisplaced['Hazard Type'] == 'Flood')| (internallyDisplaced['Hazard Type'] == 'Storm')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e91M4B7D03JH"
      },
      "source": [
        "Note remember the () inside or the code will throw an error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbLmJKu51DX7"
      },
      "source": [
        "You can use the following operators to combine conditions:\n",
        "\n",
        "\n",
        "*   & to AND\n",
        "*   | to OR\n",
        "*   ~ to NEGATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvChO0I51hzD"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced[(internallyDisplaced['Hazard Type'] == 'Flood') & (internallyDisplaced['Name'] == 'Zimbabwe')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odFVbEFJ1tsw"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced[(internallyDisplaced['Hazard Type'] == 'Flood') & ~ (internallyDisplaced['Name'] == 'Zimbabwe')]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to select the event name, year and type of hazard that happened in the UK after 2010."
      ],
      "metadata": {
        "id": "AXor68nWvE96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code below.\n",
        "# suggestion: first select hazard that happened after 2010 in the UK and then select columns.\n"
      ],
      "metadata": {
        "id": "fjG6H5QDvwC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YfHwm9C_xpQ"
      },
      "source": [
        "You can also index over a subset of a dataframe. For instance, here is an alternative way to select the first or last 10 rows of a subset of a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S15knr0WAfe4"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['New Displacements'][:10] # first 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhIuVXpeA2Wg"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['New Displacements'][-10:] # last 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxnkhNfE33de"
      },
      "source": [
        "You can store subset of dataframes on separate variables and use all methods presented above on them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgVF6ydTAaT5"
      },
      "source": [
        "Now let's introduce some new methods that are useful for numeric columns to exemplify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR-74zbe4d-A"
      },
      "source": [
        "`.min()` gives you the minimum value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "567JRK9O4RFj"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['New Displacements'].min()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKbYXIXC4i6d"
      },
      "source": [
        "`.max()` gives you the maximum value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5CFuseS4ol_"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['New Displacements'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TJPrRiA4uzK"
      },
      "source": [
        ".`mean()` gives you the mean value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd4onlyG4z2i"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['New Displacements'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tJYDTqY-_qB"
      },
      "source": [
        "`.describe()` gives you the summary statistics for numeric columns in dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvB1l8QG_AeX"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1gEaR4jGZcu"
      },
      "source": [
        "You can use `.loc` and `.iloc` to select a specific item in a dataframe. The only difference between the two is that `.loc` takes rows and columns names as arguments while `.iloc` takes their index.\n",
        "\n",
        "Note, in this case, the row names are indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mkRR_-PGcsg"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.loc[1, 'Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-1mNbMJG0lO"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.iloc[1, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRxmcZVY6AqN"
      },
      "source": [
        "You can create a new column by simply assigning it to the column name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPSdx-1W6Qus"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['Before_2010'] =  internallyDisplaced['Year'] <= 2010\n",
        "internallyDisplaced[['Event Name','Before_2010']]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a column to identify events that happened between 2010 and 2012."
      ],
      "metadata": {
        "id": "QaquuO1vik1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your code here\n"
      ],
      "metadata": {
        "id": "tu0ERMspiuJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxBr7ieh6xSM"
      },
      "source": [
        "The method `.groupby()` is used to split a dataframe into groups.\n",
        "\n",
        "Let's say you want to know how many people were displaced by a specific hazard before and after 2010."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-yRA_Iw7aI_"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.groupby(['Hazard Type', 'Before_2010'])['New Displacements'].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7pOV_qN9KOC"
      },
      "source": [
        "You can also use `.groupby()` to know how many instances of a class are in the dataframe.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVJEHqZI9i5y"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.groupby(['Hazard Type'])['Hazard Type'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When was the latest year each hazard type was recorded in each country?"
      ],
      "metadata": {
        "id": "98Go4s-ui_-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert code here\n"
      ],
      "metadata": {
        "id": "L35aM9UtjW_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1tE8aZiA6Y3"
      },
      "source": [
        "## **Dealing with missing data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS8mAAvtCHDk"
      },
      "source": [
        "The method `.isna()` tells you which items are `NaN` in your dataframem combining it with `.sum()` allows us to know how many missing values there are per column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwi0Cb70CMwc"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33iMifHlBEQz"
      },
      "source": [
        "We can deal with missing data in our dataframe by replacing them with some fix value (i.e., the sample mean)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "internallyDisplaced['New Displacements'].mean()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Zu8Zpt_ofPMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBAmb8mEBPHr"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced['New Displacements'].fillna(internallyDisplaced['New Displacements'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEvs7ScnBk2z"
      },
      "source": [
        "Note that you need to reassign the colum to `internallyDisplaced['New Displacements']` running `internallyDisplaced['New Displacements'].fillna(internallyDisplaced['New Displacements'].mean())` or your changes will not be reflected in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vdDl43mBrmC"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-kgdRmbCBa7"
      },
      "source": [
        "You can also choose to drop incomplete rows using `.dropna()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J0hgw-jBsFQ"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP85tFUuDxhd"
      },
      "source": [
        "You can also:\n",
        "\n",
        "1.   Only drop rows (or columns) where all values are `NaN` values using `.dropna(how='all')`\n",
        "2.   Put a threshold to how many non null values need to be in a row (or column) in order to keep it, using `.dropna(thresh=10)`\n",
        "3.   Choose for which column `NaN` values should be counted while dropping using `.dropna(subset=['New Displacements'])`.\n",
        "\n",
        "An example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1TyvsqRD4nZ"
      },
      "outputs": [],
      "source": [
        "internallyDisplaced.dropna(subset=['New Displacements'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-j5Ul8hsbW5"
      },
      "source": [
        "##**Data Manipulation and Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GukdH4GvjG7"
      },
      "source": [
        "Now let's go over some example of data manipulation and visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aG0e5HHVsl7Z"
      },
      "source": [
        "First, as usual, we import relevant libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEALwhxtNxW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CeeuCxGtnpJ"
      },
      "source": [
        "Take a look at the `emdat_EQ_FL_LA_1900-2022_world.xlsx` file in the files folder. You can see that this presents a header in the first 6 lines so we have to make sure that the first 6 lines are skipped when reading the excel. We can create a function that does this for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQkzXEtstQS3"
      },
      "outputs": [],
      "source": [
        "def read_EMDAT(emdatXlsFilePath):\n",
        "    rowsToSkip = range(6)\n",
        "    rawData = pd.read_excel(emdatXlsFilePath, skiprows=rowsToSkip)\n",
        "    return rawData"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj39GQssuZ_i"
      },
      "source": [
        "We can now run the function using our file path as an argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kQPsLiLugAb"
      },
      "outputs": [],
      "source": [
        "emdatFilePath = 'https://github.com/robgen/HEDSpython/raw/refs/heads/main/files/emdat_EQ_FL_LA_1900-2022_world.xlsx'\n",
        "impactData = read_EMDAT(emdatFilePath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okG-2mevu72K"
      },
      "source": [
        "We can now check what unique disaster types are reported in the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wgLhhfGuz8_"
      },
      "outputs": [],
      "source": [
        "hazTypesGeneral = pd.unique(impactData['Disaster Type'])\n",
        "hazTypesGeneral"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZo3_NOIvCi1"
      },
      "source": [
        "Yes, you can use `.unique()` both as a method and as a function. The result is exactly the same."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "impactData['Disaster Type'].unique()"
      ],
      "metadata": {
        "id": "IANjiG5jj6F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDZH4UK5vydL"
      },
      "source": [
        "Let's create a pie chart by event type in the dataframe and of events that happened after 1970.\n",
        "\n",
        "We first identify how many disasters of each type there are and sore them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2vqNvbhu1s5"
      },
      "outputs": [],
      "source": [
        "numHazTypeGeneral = []\n",
        "splitYear = 1970\n",
        "numHazTypeGeneralAfterYear = []\n",
        "for hazType in hazTypesGeneral:\n",
        "  num_hazrds = sum(impactData['Disaster Type'] == hazType)\n",
        "  numHazTypeGeneral.append(num_hazrds)\n",
        "  num_hazards_post_1970 = sum(impactData['Disaster Type'].eq(hazType) & \\\n",
        "                                          impactData['Start Year'].ge(splitYear))\n",
        "  numHazTypeGeneralAfterYear.append(num_hazards_post_1970)\n",
        "print(numHazTypeGeneral)\n",
        "print(numHazTypeGeneralAfterYear)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhkPh0IMwkgn"
      },
      "source": [
        "We then plot the values using the pyplot library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qycg2tqcw5Xd"
      },
      "outputs": [],
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.pie(numHazTypeGeneral, labels=hazTypesGeneral, autopct='%1.1f%%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEBIX9VTxCMk"
      },
      "source": [
        "We can do the same for events after 1970."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkfKeGWzw_sJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(dpi=200)\n",
        "plt.pie(numHazTypeGeneralAfterYear, labels=hazTypesGeneral, autopct='%1.1f%%')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS973MQczV_s"
      },
      "source": [
        "We now try to create two plots side by side, one with the overall hazard distribution overtime and the other with a bar chart reporting the the split in time of floods events before and after 1970."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxg2GUkCx854"
      },
      "outputs": [],
      "source": [
        "# make figure and assign axis objects\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 5), dpi=200)\n",
        "fig.subplots_adjust(wspace=0)\n",
        "\n",
        "# pie chart parameters\n",
        "explode = [0 for x in range(len(hazTypesGeneral))]\n",
        "\n",
        "ax1.pie(numHazTypeGeneral, autopct='%1.1f%%', labels=hazTypesGeneral)\n",
        "\n",
        "# bar chart parameters\n",
        "hazToSplit = 2\n",
        "specific_ratios = [numHazTypeGeneral[hazToSplit]-numHazTypeGeneralAfterYear[hazToSplit],\n",
        "                   numHazTypeGeneral[hazToSplit]]\n",
        "specific_labels = ['Before '+str(splitYear), str(splitYear)+' onwards']\n",
        "\n",
        "width = 0.2\n",
        "bc = ax2.bar(0, specific_ratios[0], width, bottom=None,\n",
        "             label=specific_labels[0], color='C'+str(hazToSplit), alpha= 0.3)\n",
        "ax2.bar_label(bc, labels=[f\"{specific_ratios[0]}\"], label_type='center')\n",
        "bc = ax2.bar(0, specific_ratios[1], width, bottom=specific_ratios[0],\n",
        "             label=specific_labels[1], color='C'+str(hazToSplit), alpha= 0.6)\n",
        "ax2.bar_label(bc, labels=[f\"{specific_ratios[1]}\"], label_type='center')\n",
        "\n",
        "ax2.set_title(hazTypesGeneral[hazToSplit])\n",
        "ax2.legend()\n",
        "ax2.axis('off')\n",
        "ax2.set_xlim(- 2.5 * width, 2.5 * width)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Peukpph0LYi"
      },
      "source": [
        "We can also plot events overtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtoOmGSn0QMG"
      },
      "outputs": [],
      "source": [
        "minYear = min(impactData['Start Year'])\n",
        "maxYear = max(impactData['Start Year'])\n",
        "\n",
        "numEventsOneYear = []\n",
        "for yr in range(minYear, maxYear+1):\n",
        "    numEventsOneYear.append(sum(impactData['Start Year'] == yr))\n",
        "\n",
        "plt.figure(dpi=200)\n",
        "plt.bar(range(minYear, maxYear+1), numEventsOneYear)\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of events [-]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTSehBe80-I-"
      },
      "source": [
        "We can also plot the frequency by event type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jiw81FrJ0ybP"
      },
      "outputs": [],
      "source": [
        "# disaggregated events\n",
        "numEventsOneYearDisagg = dict()\n",
        "for hazType in hazTypesGeneral:\n",
        "    numEventsOneYearDisagg[hazType] = []\n",
        "    for yr in range(minYear, maxYear+1):\n",
        "        numEventsOneYearDisagg[hazType].append(\n",
        "            sum(impactData['Start Year'].eq(yr) &\n",
        "                impactData['Disaster Type'].eq(hazType) ) )\n",
        "\n",
        "plt.figure(dpi=200)\n",
        "prevSeries = None\n",
        "for hazType in hazTypesGeneral:\n",
        "    plt.bar(range(minYear, maxYear+1), numEventsOneYearDisagg[hazType],\n",
        "            label=hazType, bottom=prevSeries)\n",
        "    prevSeries = numEventsOneYearDisagg[hazType]\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of events [-]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph_SKKyb4-5x"
      },
      "source": [
        "We can also map the events using the given latitude and longitude values."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we only retain values where longitude and latutitude are not NaN."
      ],
      "metadata": {
        "id": "A7eUfHNa-uaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "impactData = impactData.dropna(subset=['Longitude', 'Latitude'])"
      ],
      "metadata": {
        "id": "pOms6qoP-7pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check that we did this successfully."
      ],
      "metadata": {
        "id": "YXO21pXnfYW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "impactData[['Longitude','Latitude']]"
      ],
      "metadata": {
        "id": "7mdbQ5IEfbv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnMXU5PJ4uzB"
      },
      "source": [
        "Now let's convert latitude and longitude values into floats."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in impactData.iterrows():\n",
        "\n",
        "    try:\n",
        "        # proper number or nan\n",
        "        impactData['Longitude'][index]= float(row['Longitude'])\n",
        "    except:\n",
        "        # string\n",
        "        impactData['Longitude'][index] = float(re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", row['Longitude'])[0])\n",
        "\n",
        "    try:\n",
        "        # proper number or nan\n",
        "        impactData['Latitude'][index] = float(row['Latitude'])\n",
        "    except:\n",
        "        # string\n",
        "        impactData['Latitude'][index] = float(re.findall(r\"[-+]?(?:\\d*\\.\\d+|\\d+)\", row['Latitude'])[0])\n",
        "\n",
        "impactData[['Latitude', 'Longitude']]"
      ],
      "metadata": {
        "id": "Gyn7_qs0bnwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hazTypesGeneral = pd.unique(impactData['Disaster Type']).tolist()\n",
        "hazTypesGeneral.sort(reverse = True)\n",
        "hazTypesGeneral"
      ],
      "metadata": {
        "id": "Y276QB_hdzU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faRn3h7L5GWF"
      },
      "source": [
        "We then map them using the resulting coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygfUYsvR4378"
      },
      "outputs": [],
      "source": [
        "plt.figure(dpi=200)\n",
        "\n",
        "for ind,hazType in enumerate(hazTypesGeneral):\n",
        "    impactSliced = impactData[impactData['Disaster Type'] == hazType]\n",
        "    plt.scatter(impactSliced['Longitude'], impactSliced['Latitude'],\n",
        "                c='C'+str(ind), alpha=0.5, edgecolors='none',\n",
        "                label=hazType)\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel('Longitude [째]')\n",
        "plt.ylabel('Latitude [째]')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P8deYyQ7dqh"
      },
      "source": [
        "We can also loop over the hazard types to create separate equivalent plots by hazard.\n",
        "\n",
        "In the example below we generate three different maps for each hazard scaling the dimensions of each event location by total deaths.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp-L_67-5YeR"
      },
      "outputs": [],
      "source": [
        "scaleFactor = [0.5, 0.01]\n",
        "for ind,hazType in enumerate(hazTypesGeneral):\n",
        "  plt.figure(dpi=200)\n",
        "  impactSliced = impactData[impactData['Disaster Type'] == hazType]\n",
        "  plt.scatter(impactSliced['Longitude'], impactSliced['Latitude'],\n",
        "              c='C'+str(ind), alpha=0.5, edgecolors='none',\n",
        "              label=hazType, s=impactSliced['Total Deaths']*scaleFactor[ind])\n",
        "\n",
        "  plt.title(hazType)\n",
        "  plt.xlabel('Longitude [째]')\n",
        "  plt.ylabel('Latitude [째]')\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}